{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2MyvQTS36Aj1/iCxMvKSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shryu8902/KAERI_mini_BS/blob/main/%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C_2_2_PyOD_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%9D%B4%EC%83%81%ED%83%90%EC%A7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyOD 라이브러리를 활용한 이상탐지 실습자료\n",
        "\n",
        "본 실습자료에서는 PyOD 라이브러리를 활용하여 대표적인 머신러닝 기반 이상탐지 방법의 예제를 살펴보도록 하겠습니다.\n",
        "\n",
        "1. IRIS 데이터를 활용한 hold-out class 이상탐지 셋팅\n",
        "2. PyOD 라이브러리를 활용한 이상탐지 모델 학습\n",
        "3. 이상 탐지 성능 판단"
      ],
      "metadata": {
        "id": "ay1mpg4XnHzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 준비\n",
        "\n",
        "먼저 아래의 코드를 통해 필요 라이브러리를 불러옵니다."
      ],
      "metadata": {
        "id": "DClmf9gsnFqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyOD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pyod\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo3eeP58nngv",
        "outputId": "37cda69d-c96d-4f61-9659-38c21e121538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyOD\n",
            "  Downloading pyod-1.0.4.tar.gz (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from PyOD) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from PyOD) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from PyOD) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from PyOD) (0.56.0)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from PyOD) (1.7.3)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from PyOD) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from PyOD) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from PyOD) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->PyOD) (4.12.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->PyOD) (0.39.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->PyOD) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.0->PyOD) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->PyOD) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->PyOD) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyOD) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyOD) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyOD) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->PyOD) (1.4.4)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->PyOD) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->PyOD) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->PyOD) (2022.1)\n",
            "Building wheels for collected packages: PyOD\n",
            "  Building wheel for PyOD (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOD: filename=pyod-1.0.4-py3-none-any.whl size=165073 sha256=0ba76dff247fb32f65810237088ded662a6197fb4aa8f8a19f040c6004b8c844\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/48/a8/87d61660791c7e6b0f5c3068da7fb17ade7fdc041e864fe053\n",
            "Successfully built PyOD\n",
            "Installing collected packages: PyOD\n",
            "Successfully installed PyOD-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 준비\n",
        "\n",
        "널리 알려진 IRIS 데이터셋을 활용해보도록 하겠습니다.\n",
        "먼저 iris 데이터를 불러와서 데이터셋을 대략적으로 살펴보도록 하겠습니다."
      ],
      "metadata": {
        "id": "-CR18VIKAMZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "SvFFzS7nAxH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['label']=iris.target"
      ],
      "metadata": {
        "id": "zs8qvCoWA43a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L9tsxa_TA5Tt",
        "outputId": "0a7f788e-b248-4359-83f6-2a0c033adc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97f377f7-1fec-441a-9523-3c74ddb73870\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97f377f7-1fec-441a-9523-3c74ddb73870')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97f377f7-1fec-441a-9523-3c74ddb73870 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97f377f7-1fec-441a-9523-3c74ddb73870');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0iU8_aNvwKT_",
        "outputId": "69bbaaf3-4136-4d3c-cd37-332b1dfccdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
              "count         150.000000        150.000000         150.000000   \n",
              "mean            5.843333          3.057333           3.758000   \n",
              "std             0.828066          0.435866           1.765298   \n",
              "min             4.300000          2.000000           1.000000   \n",
              "25%             5.100000          2.800000           1.600000   \n",
              "50%             5.800000          3.000000           4.350000   \n",
              "75%             6.400000          3.300000           5.100000   \n",
              "max             7.900000          4.400000           6.900000   \n",
              "\n",
              "       petal width (cm)       label  \n",
              "count        150.000000  150.000000  \n",
              "mean           1.199333    1.000000  \n",
              "std            0.762238    0.819232  \n",
              "min            0.100000    0.000000  \n",
              "25%            0.300000    0.000000  \n",
              "50%            1.300000    1.000000  \n",
              "75%            1.800000    2.000000  \n",
              "max            2.500000    2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fa00443-3372-42c3-b231-fdc0e3e29b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "      <td>0.819232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa00443-3372-42c3-b231-fdc0e3e29b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fa00443-3372-42c3-b231-fdc0e3e29b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fa00443-3372-42c3-b231-fdc0e3e29b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IRIS 데이터는 4개의 변수로 구성되어있으며 setosa, versicolor, verginica class로 구분됩니다. \n",
        "PCA를 통해 2차원 공간상에서 데이터가 어떻게 분포되어있는지 살펴보도록 하겠습니다."
      ],
      "metadata": {
        "id": "ojFFHRLcwQG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_iris = pca.fit_transform(iris.data)\n",
        "sns.scatterplot(pca_iris[:,0],pca_iris[:,1], hue = iris.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "114al-iBubyq",
        "outputId": "7ed03422-4c7f-4770-bbf6-c340704832fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f33d314ee10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tw6kG0PKu4Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이상탐지 데이터셋 구성\n",
        "\n",
        "이제 IRIS를 활용하여 이상 탐지 문제를 위한 데이터셋을 구성해보도록하겠습니다.\n",
        "\n",
        "본 예제에서는 setosa (label=0), versicolor(label=1)를 정상 데이터로, virginica(label=2)를 비정상 데이터로 가정하여  데이터셋을 구성하도록 하겠습니다.\n",
        "\n",
        "또한 비정상 데이터의 일부를 학습데이터에 포함시켜 \n",
        "비지도학습 기반의 이상탐지 문제로 구성하였습니다.\n",
        "\n",
        "학습데이터는 순서대로 setosa, versicolor 각각 40개씩, 그리고 virginica에서 10개를 뽑아서 구성하였고, 나머지 데이터는 테스트셋으로 만들었습니다.\n",
        "\n",
        "따라서 학습 데이터셋중 약 10% 가 비정상 데이터이며, PyOD 라이브러리에서 이러한 비율을 고려할수 있는 모델은 contamination이라는 파라미터를 입력받아 사용할 수 있습니다.\n",
        "(본 예제에서는 contamination = 0.1로 사용하겠습니다.)"
      ],
      "metadata": {
        "id": "_djsrs1yxX8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_per_class =[iris.data[iris.target==i] for i in range(3)]\n",
        "train_set = np.concatenate([data_per_class[0][:40,:], data_per_class[1][:40,:], data_per_class[2][:10,:]])\n",
        "test_set = np.concatenate([data_per_class[0][40:,:], data_per_class[1][40:,:], data_per_class[2][10:,:]])\n",
        "label = np.concatenate([np.zeros(20), np.ones(40)])\n",
        "contam = 10/90"
      ],
      "metadata": {
        "id": "U--NO4OHyykB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyOD 라이브러리 활용\n",
        "\n",
        "데이터셋이 준비되어있으므로 이제 PyOD 라이브러리를 활용하여 \n",
        "다양한 이상탐지 모델들의 결과를 비교해보도록 하겠습니다.\n",
        "\n",
        "PyOD 라이브러리에서는 다양한 이상탐지 모델들을 지원하므로, 자세한 내용은 공식 document를 참고하시면 됩니다.\n",
        "https://pyod.readthedocs.io/en/latest/index.html\n",
        "\n",
        "본 예제에서는 k-nearest neighbor, isolation forest와 발표자료에서 살펴보았던 ocsvm, deep svdd, autoencoder, variational autoencoder 모델에 대한 이상탐지 결과를 비교해 보도록 하겠습니다.\n",
        "\n",
        "PyOD에서는 autoencoder, DSVDD와 같은 신경망 모델도 지원하지만 이를 위해서는 torch나 tensorflow가 함께 사용되어야 합니다.\n",
        "\n",
        "각 모델 별 hyperparameter는 라이브러리 기본값을 사용하였습니다 (신경망 모델 제외)."
      ],
      "metadata": {
        "id": "BCvZ9xmi1Cbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.deep_svdd import DeepSVDD\n",
        "from pyod.models.vae import VAE\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "lFhTOSbU6ngT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {'KNN':KNN(contamination = contam),\n",
        "          'ISOF':IForest(contamination = contam),\n",
        "          'OCSVM':OCSVM(contamination = contam),\n",
        "          'DSVDD':DeepSVDD(epochs=200, batch_size=8,contamination = contam),\n",
        "          'AE':AutoEncoder(hidden_neurons = [32,8, 2, 8, 32], epochs=200, batch_size=8,contamination = contam),\n",
        "          'VAE':VAE(encoder_neurons = [32,8,2], decoder_neurons = [2,8,32], epochs=200, batch_size=8, contamination = contam)}\n",
        "scores={'label':label}\n",
        "decisions={'label':label}"
      ],
      "metadata": {
        "id": "X_hajMFX7zXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in models:\n",
        "    models[key].fit(train_set)\n",
        "    score = models[key].decision_function(test_set)\n",
        "    result = models[key].predict(test_set)\n",
        "    scores[key] = score\n",
        "    decisions[key] = result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0IXZIcO9ShG",
        "outputId": "0ef5517e-fc71-4813-d72f-513d37d99204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " net_output (Dense)          (None, 32)                2048      \n",
            "                                                                 \n",
            " tf.math.subtract_1 (TFOpLam  (None, 32)               0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " tf.math.pow_1 (TFOpLambda)  (None, 32)                0         \n",
            "                                                                 \n",
            " tf.math.reduce_sum_1 (TFOpL  (None,)                  0         \n",
            " ambda)                                                          \n",
            "                                                                 \n",
            " tf.math.reduce_mean_1 (TFOp  ()                       0         \n",
            " Lambda)                                                         \n",
            "                                                                 \n",
            " tf.__operators__.add_1 (TFO  ()                       0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            " add_loss_1 (AddLoss)        ()                        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,304\n",
            "Trainable params: 2,304\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 1s 20ms/step - loss: 1.2777 - val_loss: 0.9598\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9611 - val_loss: 0.7286\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.7616 - val_loss: 0.6046\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.6599 - val_loss: 0.5248\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5996 - val_loss: 0.4796\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.5569 - val_loss: 0.4513\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5270 - val_loss: 0.4254\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4947 - val_loss: 0.4077\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5259 - val_loss: 0.3888\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4497 - val_loss: 0.3578\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4656 - val_loss: 0.3392\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.4027 - val_loss: 0.3249\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3751 - val_loss: 0.3064\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3786 - val_loss: 0.2894\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3407 - val_loss: 0.2785\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3251 - val_loss: 0.2688\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3134 - val_loss: 0.2602\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3014 - val_loss: 0.2489\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3134 - val_loss: 0.2396\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2806 - val_loss: 0.2350\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2711 - val_loss: 0.2263\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2647 - val_loss: 0.2169\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2633 - val_loss: 0.2124\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2484 - val_loss: 0.2068\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2425 - val_loss: 0.1934\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2342 - val_loss: 0.1878\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2252 - val_loss: 0.1842\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2204 - val_loss: 0.1801\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2121 - val_loss: 0.1727\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2026 - val_loss: 0.1596\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2176 - val_loss: 0.1560\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1937 - val_loss: 0.1511\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.1430\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1827 - val_loss: 0.1406\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1798 - val_loss: 0.1384\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1719 - val_loss: 0.1328\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1697 - val_loss: 0.1341\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1742 - val_loss: 0.1290\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1627 - val_loss: 0.1217\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1585 - val_loss: 0.1198\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1531 - val_loss: 0.1183\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1160\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1612 - val_loss: 0.1214\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1521 - val_loss: 0.1144\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1580 - val_loss: 0.1126\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1487 - val_loss: 0.1144\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1431 - val_loss: 0.1112\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1416 - val_loss: 0.1101\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1478 - val_loss: 0.1095\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1393 - val_loss: 0.1092\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1453 - val_loss: 0.1071\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1404 - val_loss: 0.1067\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1413 - val_loss: 0.1073\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1619 - val_loss: 0.1063\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1355 - val_loss: 0.1043\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1466 - val_loss: 0.1066\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1386 - val_loss: 0.1051\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1357 - val_loss: 0.1059\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1364 - val_loss: 0.1044\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1300 - val_loss: 0.1034\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1327 - val_loss: 0.1051\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1282 - val_loss: 0.1010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1302 - val_loss: 0.0995\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1276 - val_loss: 0.1019\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1260 - val_loss: 0.1021\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1267 - val_loss: 0.0997\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1336 - val_loss: 0.0982\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1292 - val_loss: 0.0991\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1254 - val_loss: 0.1015\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1275 - val_loss: 0.0975\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1231 - val_loss: 0.0981\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1232 - val_loss: 0.0976\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1258 - val_loss: 0.0948\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1197 - val_loss: 0.0953\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1255 - val_loss: 0.0942\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1162 - val_loss: 0.0952\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1166 - val_loss: 0.0930\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1210 - val_loss: 0.0944\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1154 - val_loss: 0.0949\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1145 - val_loss: 0.0934\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1096 - val_loss: 0.0919\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1106 - val_loss: 0.0923\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1091 - val_loss: 0.0907\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1077 - val_loss: 0.0901\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1099 - val_loss: 0.0904\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1225 - val_loss: 0.0909\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1090 - val_loss: 0.0910\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1147 - val_loss: 0.0898\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1082 - val_loss: 0.0894\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1075 - val_loss: 0.0885\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1165 - val_loss: 0.0897\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1062 - val_loss: 0.0892\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1061 - val_loss: 0.0875\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1054 - val_loss: 0.0879\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1068 - val_loss: 0.0887\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1060 - val_loss: 0.0906\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1060 - val_loss: 0.0891\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1049 - val_loss: 0.0887\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1032 - val_loss: 0.0890\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1027 - val_loss: 0.0896\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1033 - val_loss: 0.0877\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1049 - val_loss: 0.0869\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1037 - val_loss: 0.0873\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1044 - val_loss: 0.0865\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1074 - val_loss: 0.0860\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1014 - val_loss: 0.0901\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1048 - val_loss: 0.0895\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1092 - val_loss: 0.0853\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1034 - val_loss: 0.0963\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1019 - val_loss: 0.0856\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1103 - val_loss: 0.0880\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1004 - val_loss: 0.0855\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0993 - val_loss: 0.0846\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0990 - val_loss: 0.0861\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0990 - val_loss: 0.0867\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1004 - val_loss: 0.0860\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0981 - val_loss: 0.0860\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0990 - val_loss: 0.0847\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1097 - val_loss: 0.0860\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1031 - val_loss: 0.0868\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0989 - val_loss: 0.0875\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0979 - val_loss: 0.0845\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1009 - val_loss: 0.0881\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1035 - val_loss: 0.0902\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1103 - val_loss: 0.0828\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0988 - val_loss: 0.0895\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1053 - val_loss: 0.0843\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1053 - val_loss: 0.0886\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1011 - val_loss: 0.0876\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0994 - val_loss: 0.0809\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0979 - val_loss: 0.0878\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0980 - val_loss: 0.0852\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0977 - val_loss: 0.0841\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1073 - val_loss: 0.0818\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0992 - val_loss: 0.0884\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1039 - val_loss: 0.0863\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1005 - val_loss: 0.0839\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0975 - val_loss: 0.0897\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1033 - val_loss: 0.0834\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0978 - val_loss: 0.0828\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0953 - val_loss: 0.0829\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0943 - val_loss: 0.0833\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1037 - val_loss: 0.0838\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0953 - val_loss: 0.0853\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0965 - val_loss: 0.0845\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1000 - val_loss: 0.0822\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0953 - val_loss: 0.0877\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1032 - val_loss: 0.0857\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0946 - val_loss: 0.0842\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1072 - val_loss: 0.0836\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0981 - val_loss: 0.0834\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0981 - val_loss: 0.0823\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0956 - val_loss: 0.0822\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1076 - val_loss: 0.0852\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0947 - val_loss: 0.0833\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0948 - val_loss: 0.0841\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0955 - val_loss: 0.0816\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0946 - val_loss: 0.0846\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0939 - val_loss: 0.0850\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0944 - val_loss: 0.0860\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0931 - val_loss: 0.0873\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0941 - val_loss: 0.0830\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0942 - val_loss: 0.0806\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0934 - val_loss: 0.0827\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0929 - val_loss: 0.0825\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0928 - val_loss: 0.0825\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1023 - val_loss: 0.0849\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0980 - val_loss: 0.0801\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1011 - val_loss: 0.0862\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0932 - val_loss: 0.0845\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0945 - val_loss: 0.0813\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.0861\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0932 - val_loss: 0.0841\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0914 - val_loss: 0.0811\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0913 - val_loss: 0.0821\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0908 - val_loss: 0.0822\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0915 - val_loss: 0.0848\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0908 - val_loss: 0.0825\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0926 - val_loss: 0.0824\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0926 - val_loss: 0.0837\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0918 - val_loss: 0.0804\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.0811\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0914 - val_loss: 0.0841\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0994 - val_loss: 0.0807\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0918 - val_loss: 0.0839\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0909 - val_loss: 0.0825\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0923 - val_loss: 0.0825\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.0798\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.0843\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0922 - val_loss: 0.0821\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0946 - val_loss: 0.0877\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0905 - val_loss: 0.0830\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0925 - val_loss: 0.0820\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0905 - val_loss: 0.0803\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0919 - val_loss: 0.0808\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0894 - val_loss: 0.0817\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0921 - val_loss: 0.0809\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0945 - val_loss: 0.0851\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0899 - val_loss: 0.0776\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0918 - val_loss: 0.0795\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                160       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 24        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                288       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 926\n",
            "Trainable params: 926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 31ms/step - loss: 2.7321 - val_loss: 2.1939\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5398 - val_loss: 2.1052\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4532 - val_loss: 2.0272\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2331 - val_loss: 1.9615\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1768 - val_loss: 1.8957\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3168 - val_loss: 1.8417\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.0403 - val_loss: 1.7929\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 2.1176 - val_loss: 1.7486\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9758 - val_loss: 1.7050\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0376 - val_loss: 1.6594\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8815 - val_loss: 1.6211\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.9609 - val_loss: 1.5834\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8140 - val_loss: 1.5478\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8179 - val_loss: 1.5091\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7874 - val_loss: 1.4774\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.7127 - val_loss: 1.4522\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6693 - val_loss: 1.4285\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6598 - val_loss: 1.4040\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6472 - val_loss: 1.3831\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6010 - val_loss: 1.3629\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5974 - val_loss: 1.3447\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5907 - val_loss: 1.3266\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5714 - val_loss: 1.3099\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5530 - val_loss: 1.2925\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.5112 - val_loss: 1.2768\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.5115 - val_loss: 1.2606\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4704 - val_loss: 1.2460\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4798 - val_loss: 1.2328\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4526 - val_loss: 1.2197\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4446 - val_loss: 1.2076\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.4265 - val_loss: 1.1962\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.4066 - val_loss: 1.1859\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3910 - val_loss: 1.1764\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3901 - val_loss: 1.1669\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3617 - val_loss: 1.1573\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3610 - val_loss: 1.1486\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3543 - val_loss: 1.1403\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3531 - val_loss: 1.1321\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3485 - val_loss: 1.1235\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3317 - val_loss: 1.1162\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3260 - val_loss: 1.1083\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3190 - val_loss: 1.1014\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.3166 - val_loss: 1.0926\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2894 - val_loss: 1.0856\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2701 - val_loss: 1.0784\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2724 - val_loss: 1.0706\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2791 - val_loss: 1.0646\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2691 - val_loss: 1.0591\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2613 - val_loss: 1.0539\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2491 - val_loss: 1.0486\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2553 - val_loss: 1.0438\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2487 - val_loss: 1.0384\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2321 - val_loss: 1.0339\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2326 - val_loss: 1.0286\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2449 - val_loss: 1.0216\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2237 - val_loss: 1.0164\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2193 - val_loss: 1.0122\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2229 - val_loss: 1.0077\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2099 - val_loss: 1.0024\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2145 - val_loss: 0.9982\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.2059 - val_loss: 0.9942\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1991 - val_loss: 0.9904\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1966 - val_loss: 0.9865\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.2010 - val_loss: 0.9831\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1980 - val_loss: 0.9798\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1915 - val_loss: 0.9770\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1745 - val_loss: 0.9739\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1738 - val_loss: 0.9702\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1817 - val_loss: 0.9665\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1714 - val_loss: 0.9633\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1729 - val_loss: 0.9607\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1647 - val_loss: 0.9573\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1611 - val_loss: 0.9547\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1641 - val_loss: 0.9520\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1634 - val_loss: 0.9495\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1564 - val_loss: 0.9472\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1598 - val_loss: 0.9449\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1590 - val_loss: 0.9428\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1498 - val_loss: 0.9413\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1477 - val_loss: 0.9394\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1440 - val_loss: 0.9374\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1341 - val_loss: 0.9353\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1370 - val_loss: 0.9338\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1392 - val_loss: 0.9313\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1361 - val_loss: 0.9289\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1371 - val_loss: 0.9260\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1370 - val_loss: 0.9224\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1275 - val_loss: 0.9203\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1278 - val_loss: 0.9185\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1223 - val_loss: 0.9167\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1240 - val_loss: 0.9151\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1288 - val_loss: 0.9139\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1183 - val_loss: 0.9123\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1116 - val_loss: 0.9117\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1201 - val_loss: 0.9102\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1144 - val_loss: 0.9077\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1191 - val_loss: 0.9056\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1169 - val_loss: 0.9039\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1125 - val_loss: 0.9027\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1115 - val_loss: 0.9016\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1137 - val_loss: 0.9003\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1094 - val_loss: 0.8994\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1025 - val_loss: 0.8982\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1088 - val_loss: 0.8971\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1072 - val_loss: 0.8961\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.1058 - val_loss: 0.8951\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1057 - val_loss: 0.8944\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.1003 - val_loss: 0.8926\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0998 - val_loss: 0.8916\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0986 - val_loss: 0.8910\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0992 - val_loss: 0.8903\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0980 - val_loss: 0.8897\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0934 - val_loss: 0.8891\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0942 - val_loss: 0.8885\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0971 - val_loss: 0.8871\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0924 - val_loss: 0.8862\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0947 - val_loss: 0.8859\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0941 - val_loss: 0.8853\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0878 - val_loss: 0.8839\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0918 - val_loss: 0.8828\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0893 - val_loss: 0.8810\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0850 - val_loss: 0.8800\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0817 - val_loss: 0.8795\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0899 - val_loss: 0.8787\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0825 - val_loss: 0.8783\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0861 - val_loss: 0.8774\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0873 - val_loss: 0.8768\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0856 - val_loss: 0.8766\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0833 - val_loss: 0.8762\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0881 - val_loss: 0.8756\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0838 - val_loss: 0.8743\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0753 - val_loss: 0.8734\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0822 - val_loss: 0.8729\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0806 - val_loss: 0.8725\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0893 - val_loss: 0.8721\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0775 - val_loss: 0.8717\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0788 - val_loss: 0.8716\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0777 - val_loss: 0.8712\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0842 - val_loss: 0.8705\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0758 - val_loss: 0.8695\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0727 - val_loss: 0.8689\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0736 - val_loss: 0.8683\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0754 - val_loss: 0.8680\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0701 - val_loss: 0.8677\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0701 - val_loss: 0.8677\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0770 - val_loss: 0.8680\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0747 - val_loss: 0.8679\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0765 - val_loss: 0.8673\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0758 - val_loss: 0.8667\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0693 - val_loss: 0.8663\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0727 - val_loss: 0.8661\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0771 - val_loss: 0.8664\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0713 - val_loss: 0.8658\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0650 - val_loss: 0.8654\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0691 - val_loss: 0.8640\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0713 - val_loss: 0.8634\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0674 - val_loss: 0.8632\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0689 - val_loss: 0.8631\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0683 - val_loss: 0.8632\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0632 - val_loss: 0.8630\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0671 - val_loss: 0.8624\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0678 - val_loss: 0.8621\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0670 - val_loss: 0.8617\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0681 - val_loss: 0.8614\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0655 - val_loss: 0.8611\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0681 - val_loss: 0.8608\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0607 - val_loss: 0.8608\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0604 - val_loss: 0.8602\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0693 - val_loss: 0.8596\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0622 - val_loss: 0.8593\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0697 - val_loss: 0.8591\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0673 - val_loss: 0.8588\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0629 - val_loss: 0.8588\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0633 - val_loss: 0.8588\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0632 - val_loss: 0.8584\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0638 - val_loss: 0.8582\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0645 - val_loss: 0.8582\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0666 - val_loss: 0.8578\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0648 - val_loss: 0.8574\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0600 - val_loss: 0.8574\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0603 - val_loss: 0.8574\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0557 - val_loss: 0.8569\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0588 - val_loss: 0.8568\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0607 - val_loss: 0.8568\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0592 - val_loss: 0.8566\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0602 - val_loss: 0.8561\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0614 - val_loss: 0.8561\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0674 - val_loss: 0.8559\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0578 - val_loss: 0.8559\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0550 - val_loss: 0.8557\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0592 - val_loss: 0.8556\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0609 - val_loss: 0.8557\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0602 - val_loss: 0.8556\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0595 - val_loss: 0.8555\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0575 - val_loss: 0.8548\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0599 - val_loss: 0.8544\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.0609 - val_loss: 0.8541\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0602 - val_loss: 0.8540\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0580 - val_loss: 0.8539\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.0569 - val_loss: 0.8538\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4)            20          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 32)           160         ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 32)           0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 8)            264         ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 8)            0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 2)            18          ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 2)            0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 2)            6           ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 2)            6           ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 2)            0           ['dense_14[0][0]',               \n",
            "                                                                  'dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 474\n",
            "Trainable params: 474\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 8)                 24        \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                288       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456\n",
            "Trainable params: 456\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " model_3 (Functional)           [(None, 2),          474         ['input_3[0][0]']                \n",
            "                                 (None, 2),                                                       \n",
            "                                 (None, 2)]                                                       \n",
            "                                                                                                  \n",
            " model_4 (Functional)           (None, 4)            456         ['model_3[0][2]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4)            20          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 32)           160         ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 32)           0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 8)            264         ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 8)            0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 2)            18          ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 2)            0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 2)            6           ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 2)            6           ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['dense_15[0][0]']               \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda)    (None, 2)            0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
            " )                                                                'tf.math.square[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 2)            0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_2[0][0]',     \n",
            " )                                                                'tf.math.exp[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_2 (TFOpLamb  (None,)             0           ['tf.math.subtract_3[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOpLamb  (None, 4)           0           ['model_4[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)           (None, 4)            0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_2[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.squared_difference (TF  (None, 4)           0           ['tf.convert_to_tensor[0][0]',   \n",
            " OpLambda)                                                        'tf.cast[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.subtract_4 (TFOpLambda  (None,)             0           ['tf.math.multiply_1[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_2 (TFOpLam  (None,)             0           ['tf.math.squared_difference[0][0\n",
            " bda)                                                            ]']                              \n",
            "                                                                                                  \n",
            " tf.math.abs (TFOpLambda)       (None,)              0           ['tf.math.subtract_4[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None,)             0           ['tf.math.abs[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None,)             0           ['tf.math.multiply[0][0]',       \n",
            " mbda)                                                            'tf.math.multiply_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_3 (TFOpLam  ()                  0           ['tf.__operators__.add_3[0][0]'] \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " add_loss_2 (AddLoss)           ()                   0           ['tf.math.reduce_mean_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 930\n",
            "Trainable params: 930\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 35ms/step - loss: 5.5597 - val_loss: 3.5111\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0412 - val_loss: 3.4601\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0574 - val_loss: 3.4129\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.2065 - val_loss: 3.3827\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.1307 - val_loss: 3.3303\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.0475 - val_loss: 3.3093\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.8247 - val_loss: 3.2441\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9679 - val_loss: 3.2398\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.8538 - val_loss: 3.2109\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5260 - val_loss: 3.1857\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4966 - val_loss: 3.1559\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.5417 - val_loss: 3.0874\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7860 - val_loss: 3.0740\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.6665 - val_loss: 2.8809\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5406 - val_loss: 2.9134\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4190 - val_loss: 2.7742\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1616 - val_loss: 2.8442\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7048 - val_loss: 2.8231\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1747 - val_loss: 2.8204\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5595 - val_loss: 2.8924\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3775 - val_loss: 2.5811\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3080 - val_loss: 2.7753\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2220 - val_loss: 2.7250\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1836 - val_loss: 2.7598\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2605 - val_loss: 2.6657\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1086 - val_loss: 2.6960\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1746 - val_loss: 2.6930\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0047 - val_loss: 2.6349\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4840 - val_loss: 2.6777\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1193 - val_loss: 2.6739\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4105 - val_loss: 2.7039\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8427 - val_loss: 2.6911\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4120 - val_loss: 2.6600\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0572 - val_loss: 2.6653\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.6888 - val_loss: 2.7166\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.9359 - val_loss: 2.6548\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0955 - val_loss: 2.7453\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1641 - val_loss: 2.6742\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8274 - val_loss: 2.7039\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4486 - val_loss: 2.6215\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3166 - val_loss: 2.7231\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4031 - val_loss: 2.7000\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9287 - val_loss: 2.6908\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0189 - val_loss: 2.7018\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0443 - val_loss: 2.7016\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0389 - val_loss: 2.6419\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9180 - val_loss: 2.7034\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9807 - val_loss: 2.7465\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1193 - val_loss: 2.6711\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3159 - val_loss: 2.6751\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0792 - val_loss: 2.6868\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8902 - val_loss: 2.6843\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1497 - val_loss: 2.6499\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9041 - val_loss: 2.6653\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1750 - val_loss: 2.7488\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2084 - val_loss: 2.7280\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0446 - val_loss: 2.6281\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0178 - val_loss: 2.7227\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0432 - val_loss: 2.7009\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9054 - val_loss: 2.6663\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0863 - val_loss: 2.6998\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0704 - val_loss: 2.7072\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3972 - val_loss: 2.6460\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.0812 - val_loss: 2.6846\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1111 - val_loss: 2.6899\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0214 - val_loss: 2.6937\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3186 - val_loss: 2.6834\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0158 - val_loss: 2.7005\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8555 - val_loss: 2.6558\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1003 - val_loss: 2.7215\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0198 - val_loss: 2.6420\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9528 - val_loss: 2.6787\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 4.0873 - val_loss: 2.6854\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1976 - val_loss: 2.7110\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9918 - val_loss: 2.6889\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2108 - val_loss: 2.7058\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8685 - val_loss: 2.6629\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.3924 - val_loss: 2.6908\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8253 - val_loss: 2.6694\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0566 - val_loss: 2.7069\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7608 - val_loss: 2.6931\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1372 - val_loss: 2.6658\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8591 - val_loss: 2.7011\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9317 - val_loss: 2.6903\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1728 - val_loss: 2.6527\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.4338 - val_loss: 2.6569\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2542 - val_loss: 2.7188\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8668 - val_loss: 2.6828\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1670 - val_loss: 2.6917\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0009 - val_loss: 2.6962\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4362 - val_loss: 2.6786\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2443 - val_loss: 2.7007\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8913 - val_loss: 2.6598\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9571 - val_loss: 2.6824\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0820 - val_loss: 2.7116\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0275 - val_loss: 2.6829\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8740 - val_loss: 2.6948\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7623 - val_loss: 2.6826\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8158 - val_loss: 2.6914\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9818 - val_loss: 2.6871\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0666 - val_loss: 2.6980\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.7919 - val_loss: 2.7056\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0425 - val_loss: 2.6729\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2884 - val_loss: 2.6857\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0515 - val_loss: 2.7036\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0523 - val_loss: 2.6802\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.1201 - val_loss: 2.6886\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1517 - val_loss: 2.7000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0436 - val_loss: 2.6829\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8002 - val_loss: 2.7003\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1742 - val_loss: 2.6659\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1213 - val_loss: 2.6935\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0280 - val_loss: 2.6865\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9171 - val_loss: 2.7002\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0690 - val_loss: 2.7023\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8408 - val_loss: 2.7062\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0751 - val_loss: 2.6820\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4413 - val_loss: 2.7094\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0713 - val_loss: 2.6963\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9997 - val_loss: 2.6912\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0879 - val_loss: 2.6961\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9222 - val_loss: 2.6998\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2048 - val_loss: 2.6998\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7643 - val_loss: 2.6816\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.5051 - val_loss: 2.7003\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8630 - val_loss: 2.6855\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9480 - val_loss: 2.6907\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0594 - val_loss: 2.6944\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0928 - val_loss: 2.7000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0502 - val_loss: 2.6885\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9414 - val_loss: 2.6841\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7339 - val_loss: 2.6965\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9556 - val_loss: 2.6855\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2023 - val_loss: 2.6924\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0616 - val_loss: 2.6899\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3453 - val_loss: 2.6913\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7701 - val_loss: 2.6737\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.2350 - val_loss: 2.6833\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0837 - val_loss: 2.6972\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7747 - val_loss: 2.6987\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0159 - val_loss: 2.6972\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.3789 - val_loss: 2.6919\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9576 - val_loss: 2.6925\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9448 - val_loss: 2.6924\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9713 - val_loss: 2.6908\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8232 - val_loss: 2.7058\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0527 - val_loss: 2.7030\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1928 - val_loss: 2.7020\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4340 - val_loss: 2.6945\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2190 - val_loss: 2.6994\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9326 - val_loss: 2.6924\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1989 - val_loss: 2.6957\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0300 - val_loss: 2.6888\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9118 - val_loss: 2.6932\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8353 - val_loss: 2.6957\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4262 - val_loss: 2.7040\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9278 - val_loss: 2.6936\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0093 - val_loss: 2.7044\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0411 - val_loss: 2.6963\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1462 - val_loss: 2.6927\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1539 - val_loss: 2.6944\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8605 - val_loss: 2.6912\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0298 - val_loss: 2.6895\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9184 - val_loss: 2.6878\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1855 - val_loss: 2.6883\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0882 - val_loss: 2.6978\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0495 - val_loss: 2.6804\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7793 - val_loss: 2.6932\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9724 - val_loss: 2.6968\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8641 - val_loss: 2.6907\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.8045 - val_loss: 2.7007\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0552 - val_loss: 2.6958\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0299 - val_loss: 2.6820\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0294 - val_loss: 2.6942\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0409 - val_loss: 2.6892\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9772 - val_loss: 2.6949\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.7911 - val_loss: 2.6865\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.7857 - val_loss: 2.6865\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.1121 - val_loss: 2.6928\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9492 - val_loss: 2.6929\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9445 - val_loss: 2.6966\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4503 - val_loss: 2.6938\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.8496 - val_loss: 2.6743\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0635 - val_loss: 2.6823\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8124 - val_loss: 2.6996\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8802 - val_loss: 2.7006\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0781 - val_loss: 2.6935\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0322 - val_loss: 2.7000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0258 - val_loss: 2.6917\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 4.0336 - val_loss: 2.6921\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8989 - val_loss: 2.6950\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.2797 - val_loss: 2.6971\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.9496 - val_loss: 2.6920\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8704 - val_loss: 2.6983\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8108 - val_loss: 2.6895\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.8295 - val_loss: 2.6950\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 3.9230 - val_loss: 2.6935\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.4717 - val_loss: 2.6932\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 4.0647 - val_loss: 2.7041\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.7295 - val_loss: 2.6915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 정리\n",
        "\n",
        "이제 PyOD 모델별로 이상탐지 성능 평가 결과를 비교해보도록하겠습니다.\n",
        "\n",
        "다음의 코드를 통해 모델별로 ROC 그래프와 AUROC를 계산하였습니다."
      ],
      "metadata": {
        "id": "ofsaobpGKD3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "9s53Lrdd9ULF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "for i, key in enumerate(models):\n",
        "    fpr,tpr, thresh = metrics.roc_curve(df_scores.label, df_scores[key])\n",
        "    auc = metrics.auc(fpr,tpr)\n",
        "    plt.plot(fpr, tpr, label = key + '_AUC({})'.format(auc))\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "2SnlkGkn9k0V",
        "outputId": "4800007d-5d26-4dee-cc28-5ed5e8916b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f33d3077850>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음은 contamination 비율에 따라 pyod에서 자동적으로 설정된 threshold를 기준으로 모델별 최종 정상/이상 분류결과에 대한 그래프입니다.\n",
        "X축은 각 입력 데이터의 인덱스이고 Y축은 모델별 최종 분류 결과입니다. (0 : 정상, 1 : 비정상)"
      ],
      "metadata": {
        "id": "gRuL-HxgKRFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame(decisions)\n",
        "\n",
        "for i, key in enumerate(models):\n",
        "    plt.scatter(np.arange(60), df_result[key]+i*0.01, label = key)\n",
        "plt.scatter(np.arange(60), df_result.label, marker='*',color='k', label = 'True_label')\n",
        "\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('label')\n",
        "plt.title('Anomaly detection results')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "XMaXcsw1ERfE",
        "outputId": "2af5cc72-5bde-46e2-c175-756a2526c6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f336ada56d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 IRIS 데이터셋과 PyOD 라이브러리를 활용하여 간단한 이상탐지 모델을 학습시키고 이상탐지 결과를 비교해보았습니다. \n",
        "\n",
        "이상탐지 문제에서는 데이터셋에따라 모델별 성능이 상이 할 수 있으며, \n",
        "\n",
        "PyOD 라이브러리를 활용하면 다양한 모델에 대한 적용 결과를 쉽게 확인 할 수 있습니다."
      ],
      "metadata": {
        "id": "qRCaD0EWLNDB"
      }
    }
  ]
}